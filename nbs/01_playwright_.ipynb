{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# playwright_\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp playwright_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import asyncio\n",
    "from playwright.async_api import async_playwright, Page, Playwright, Browser\n",
    "import traceback\n",
    "import re\n",
    "from fastcore.all import *\n",
    "from urllib.parse import urlparse, urlencode, quote_plus, unquote\n",
    "from scraper.core import *\n",
    "import requests\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "DEBUG = True\n",
    "BROWSERS = {\n",
    "    \"ch\": lambda pw: pw.chromium,\n",
    "    \"ff\": lambda pw: pw.firefox,\n",
    "    \"wk\": lambda pw: pw.webkit,\n",
    "}\n",
    "\n",
    "async def get_brow(pw: Playwright, brow_n: str):\n",
    "    \"\"\"\n",
    "    return browser_name object from \n",
    "    ch -> chromium\n",
    "    ff -> firefox\n",
    "    wk -> webkit\n",
    "    \"\"\"\n",
    "    browser_func = BROWSERS.get(brow_n)\n",
    "    if not browser_func:\n",
    "        raise ValueError(f\"Unknown browser: {brow_n}\")\n",
    "    return await browser_func(pw).launch(headless=DEBUG==False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launched wk\n",
      "Launched ch\n",
      "Launched ff\n"
     ]
    }
   ],
   "source": [
    "async with async_playwright() as pw:\n",
    "    async def _test(bn):\n",
    "        browser = await get_brow(pw, bn)\n",
    "        assert browser is not None\n",
    "        print(f\"Launched {bn}\")\n",
    "        await browser.close()\n",
    "\n",
    "    await asyncio.gather(\n",
    "        _test(\"ch\"),\n",
    "        _test(\"ff\"),\n",
    "        _test(\"wk\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "async def get_href(page:Page):\n",
    "    \"\"\"\n",
    "    Takes in Page object and get back all the href which are not part of `ignore_href`.\\n\n",
    "    It is doen by loop through all the a tags.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        links = [await tag.get_attribute('href')  for tag in await page.query_selector_all('a')]\n",
    "        return [ link for link in links if valid_href(link) ]\n",
    "    except Exception as e:\n",
    "        print(f\"failed for {await page.url}\")\n",
    "        traceback.print_exc()\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hrefs=['https://nbdev.fast.ai/', 'https://nbdev.fast.ai/getting_started.html', 'https://nbdev.fast.ai/tutorials/tutorial.html', 'https://nbdev.fast.ai/blog/', 'https://nbdev.fast.ai/#', 'https://github.com/fastai/nbdev/issues', 'https://forums.fast.ai/', 'https://nbdev.fast.ai/getting_started.html#faq', 'https://github.com/fastai/nbdev', 'https://twitter.com/fastdotai', 'https://nbdev.fast.ai/getting_started.html', 'https://nbdev.fast.ai/getting_started.html', 'https://github.com/fastai/nbdev/issues/new']\n"
     ]
    }
   ],
   "source": [
    "async with async_playwright() as pw:\n",
    "    brow = await get_brow(pw, \"ch\")\n",
    "    page = await brow.new_page()\n",
    "    await page.goto('https://nbdev.fast.ai/') \n",
    "    hrefs = await get_href(page)\n",
    "    await page.close(); await brow.close()\n",
    "\n",
    "assert len(hrefs) != 0, \"Expected href to contain links, but it is empty.\"\n",
    "print(f\"{hrefs=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i='https://nbdev.fast.ai/' ->  https://nbdev.fast.ai\n",
      "i='https://nbdev.fast.ai/getting_started.html' ->  https://nbdev.fast.ai/getting_started.html\n",
      "i='https://nbdev.fast.ai/tutorials/tutorial.html' ->  https://nbdev.fast.ai/tutorials/tutorial.html\n",
      "i='https://nbdev.fast.ai/blog/' ->  https://nbdev.fast.ai/blog\n",
      "i='https://nbdev.fast.ai/#' ->  None\n",
      "i='https://github.com/fastai/nbdev/issues' ->  None\n",
      "i='https://forums.fast.ai/' ->  None\n",
      "i='https://nbdev.fast.ai/getting_started.html#faq' ->  None\n",
      "i='https://github.com/fastai/nbdev' ->  None\n",
      "i='https://twitter.com/fastdotai' ->  None\n",
      "i='https://nbdev.fast.ai/getting_started.html' ->  https://nbdev.fast.ai/getting_started.html\n",
      "i='https://nbdev.fast.ai/getting_started.html' ->  https://nbdev.fast.ai/getting_started.html\n",
      "i='https://github.com/fastai/nbdev/issues/new' ->  None\n"
     ]
    }
   ],
   "source": [
    "for i in hrefs:\n",
    "    print(f\"{i=} -> \", hydrate_links(\"nbdev.fast.ai\", i) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nbdev.fast.ai'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "url = 'https://nbdev.fast.ai/'\n",
    "fn = \"text\"\n",
    "local_domain = urlparse(url).netloc\n",
    "local_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../text/nbdev.fast.ai\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "domain_dir = Path(f\"../{fn}/{local_domain}\")\n",
    "print(domain_dir)\n",
    "domain_dir.mkdir(exist_ok=True, parents=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "log_err = lambda func, url, err: print(f\"Error in {func=}\\n{url=}\\n{err}\")\n",
    "\n",
    "def download_file(url:str, fn:Path='.'):\n",
    "    \"\"\"\n",
    "    Downloads a file from the specified URL and saves it to the given path.\n",
    "    Args:\n",
    "        url (str): The URL from which to download the file.\n",
    "        fn (Path): The destination file path to save the downloaded content.\n",
    "    Raises:\n",
    "        Exception: If an error occurs during the download or saving process.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        resp = requests.get(url)\n",
    "        if resp.status_code == 200:\n",
    "            with open(fn, 'wb') as f:\n",
    "                f.write(resp.content)\n",
    "    except Exception as e:\n",
    "        log_err('download_file', url, e)\n",
    "        traceback.print_exc()\n",
    "Path('Test/dummy.pdf').unlink(missing_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "dir_n = Path('Test/')\n",
    "dir_n.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_file('https://www.w3.org/WAI/ER/tests/xhtml/testfiles/resources/pdf/dummy.pdf', \n",
    "              Path('Test/dummy.pdf'))\n",
    "assert Path('Test/dummy.pdf').exists(), \"File not found\"\n",
    "assert Path('Test/dummy.pdf').stat().st_size > 0, \"File is empty\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "async def download_html(brow:Browser, url:str, fn:Path):\n",
    "        \"\"\"\n",
    "        takes in url either ending with .html or any abs adress\n",
    "        retruns all the href with the abs links\n",
    "        \"\"\"\n",
    "        \n",
    "        page = await brow.new_page()\n",
    "\n",
    "        try:\n",
    "            await page.goto(url) \n",
    "            #c_typ =  resp.headers.get('content-type', '').lower()\n",
    "            #c_typ_ext = [k for k, v in ALLOWED_EXT_CONTENT_TYPS.items() if v in c_typ][0][1:]\n",
    "            #print(f\"{url=}\\n{fn=}\\n{f_ext=}\\n{c_typ=}\\n{c_typ_ext=}\")\n",
    "            \n",
    "            with open(fn, 'w', encoding='utf-8') as f:\n",
    "                    f.write(await page.content())\n",
    "            return await get_href(page)\n",
    " \n",
    "        except Exception as e:\n",
    "            log_err('download_html', url, e)\n",
    "            traceback.print_exc()\n",
    "        finally:\n",
    "            await page.close()\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with async_playwright() as pw:\n",
    "    brow = await get_brow(pw, \"ch\")\n",
    "    assert len(await download_html(brow, url, Path('./Text/'))) > 0 \n",
    "    await brow.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import traceback\n",
    "\n",
    "async def crawl(url: str, dir_n: Path, brow_typ: str = \"ch\"):\n",
    "    \"\"\"\n",
    "    Asynchronously crawls and downloads HTML and specific file types within a given domain.\n",
    "\n",
    "    Args:\n",
    "        url (str): The starting URL for crawling.\n",
    "        dir_n (Path): The directory path where downloaded files will be saved.\n",
    "        brow_typ (str): The browser type (default is \"ch\").\n",
    "    \"\"\"\n",
    "    local_domain = urlparse(url).netloc\n",
    "    queue = deque([url])\n",
    "    seen = set()\n",
    "\n",
    "    # Create directory for the domain\n",
    "    dir_n = dir_n / local_domain\n",
    "    dir_n.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    async with async_playwright() as pw:\n",
    "        brow = await get_brow(pw, brow_typ)\n",
    "        while queue:\n",
    "            url = queue.pop()\n",
    "            try:\n",
    "                if url and url not in seen:\n",
    "                    #print(f\"{url=}\")\n",
    "                    fn = get_fn_from_url(url)\n",
    "                    f_ext = fn.split('.')[-1]  # Get file extension\n",
    "\n",
    "                    if f_ext == 'html':\n",
    "                        links = await download_html(brow, url, dir_n / fn)\n",
    "                        # Ensure each link is valid for deque.extend\n",
    "                        queue.extend([hydrate_links(local_domain, i) for i in links])\n",
    "                    elif '.' + f_ext in ['.pdf', '.doc', '.docx', '.odt', '.xls', '.xlsx', '.ppt', '.pptx', '.txt', '.csv']:\n",
    "                        download_file(url, dir_n / fn)\n",
    "                    else:\n",
    "                        print(f\"Cannot process {url=}\")\n",
    "                seen.add(url)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {url=}:\")\n",
    "                traceback.print_exception(type(e), e, e.__traceback__)\n",
    "\n",
    "        await brow.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await crawl('https://fastcore.fast.ai/', Path('Test/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "assert len(Path('Test/fastcore.fast.ai').ls()) != 0\n",
    "%rm -rf Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
